% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interpret.R
\name{interpret}
\alias{interpret}
\title{interpret}
\usage{
interpret(
  x,
  context = NULL,
  n_pathways = 20,
  model = "deepseek-chat",
  api_key = NULL,
  task = "interpretation",
  prior = NULL,
  add_ppi = FALSE,
  gene_fold_change = NULL
)
}
\arguments{
\item{x}{An enrichment result object (e.g., `enrichResult` or `gseaResult`).}

\item{context}{A string describing the experimental background (e.g., "scRNA-seq of mouse myocardial infarction at day 3").}

\item{n_pathways}{Number of top significant pathways to include in the analysis. Default is 20.}

\item{model}{The LLM model to use. Default is "deepseek-chat". Supported models include "deepseek-chat", "glm-4", "qwen-turbo" etc.}

\item{api_key}{The API key for the LLM. If NULL, it tries to fetch from `getOption('yulab_translate')` based on the model.}

\item{task}{Task type, default is "interpretation". Other options include "cell_type"/"annotation" and "phenotype"/"phenotyping".}

\item{prior}{Optional prior knowledge (e.g., a biological hypothesis) to guide the task.}

\item{add_ppi}{Boolean, whether to use PPI network integration.}

\item{gene_fold_change}{Named vector of logFC for expression context.}
}
\value{
A character string containing the LLM-generated interpretation.
}
\description{
Interpret enrichment results using Large Language Models (LLM)
}
\details{
This function sends the enrichment results (top significant pathways) along with 
an optional experimental context to an LLM (e.g., DeepSeek) to generate 
a biological interpretation, hypothesis, and narrative suitable for a paper.
}
\author{
Guangchuang Yu
}
