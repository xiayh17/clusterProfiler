% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interpret.R
\name{interpret}
\alias{interpret}
\title{Interpret Enrichment Results Using LLMs}
\usage{
interpret(
  x,
  context = NULL,
  n_pathways = 20,
  model = "deepseek:deepseek-chat",
  task = "interpretation",
  prior = NULL,
  add_ppi = FALSE,
  gene_fold_change = NULL,
  max_tokens = 8192,
  temperature = 0.3,
  verbose = FALSE
)
}
\arguments{
\item{x}{An enrichment result object (`enrichResult`, `gseaResult`,
`compareClusterResult`, or a `data.frame` with pathway columns).}

\item{context}{A string describing the experimental background
(e.g., "scRNA-seq of mouse myocardial infarction at day 3").}

\item{n_pathways}{Number of top significant pathways to include. Default 20.}

\item{model}{The LLM model in `provider:model` format
(e.g., "deepseek:deepseek-chat", "gemini:gemini-2.5-flash").
Bare model names are supported with a warning (e.g., "deepseek-chat").}

\item{task}{Task type: "interpretation" (default), "cell_type"/"annotation",
or "phenotype"/"phenotyping".}

\item{prior}{Optional prior knowledge or preliminary annotation to guide the task.}

\item{add_ppi}{Logical, whether to query STRING PPI network data. Default FALSE.}

\item{gene_fold_change}{Named numeric vector of log fold changes for expression context.}

\item{max_tokens}{Maximum tokens for the LLM response. Default 8192.
Some models (especially reasoning models) may need much higher values
(e.g., 16384 or more) to produce complete structured output.}

\item{temperature}{Sampling temperature. Default 0.3.}

\item{verbose}{Logical, whether to print debug messages showing raw API
responses, token usage, and JSON parsing details. Default FALSE.
Equivalent to setting `options(aisdk.debug = TRUE)` for the call.}
}
\value{
An `interpretation` object (list) with task-specific fields.
  For "interpretation": overview, key_mechanisms, hypothesis, narrative, etc.
  For "annotation": cell_type, confidence, reasoning, markers, etc.
  For "phenotype": phenotype, confidence, reasoning, key_processes, etc.
}
\description{
Functions for interpreting functional enrichment analysis results using
Large Language Models. Supports single-call interpretation, multi-agent
deep analysis, and hierarchical cluster strategies.

Built on top of aisdk's `generate_object()` for reliable structured output,
and the Agent/Session system for multi-agent pipelines.

Sends enrichment results along with optional experimental context to an LLM
to generate a structured biological interpretation, hypothesis, and narrative
suitable for a publication.
}
\details{
Uses `generate_object()` internally for reliable structured output with
automatic JSON repair, eliminating manual parsing failures.
}
\examples{
\dontrun{
# Basic usage with a data frame
df <- data.frame(
  ID = c("GO:0006915", "GO:0008284"),
  Description = c("apoptotic process", "positive regulation of proliferation"),
  GeneRatio = c("10/100", "20/100"),
  p.adjust = c(0.01, 0.02),
  geneID = c("TP53/BAX", "MYC/CCND1/CDK4")
)
res <- interpret(df, model = "deepseek:deepseek-chat",
                 context = "Cancer proliferation study")
print(res)
}
}
